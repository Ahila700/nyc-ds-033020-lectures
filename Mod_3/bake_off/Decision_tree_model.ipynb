{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(context='paper', style='darkgrid', rc={'figure.facecolor':'white'}, font_scale=1.2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.read_csv('Cleaned_data_w_dummies.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_3.drop('Default', axis = 1)\n",
    "y = df_3['Default']\n",
    "feature_cols = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = df_3[df_3['Default'] == 1]\n",
    "no_default = df_3[df_3['Default'] == 0]\n",
    "classes = ['default', 'no_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "final_scaler = scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(data=scaler.transform(X_train), columns = X.columns)\n",
    "X_test = pd.DataFrame(data=scaler.transform(X_test), columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 0.5232658072437077\n",
      "Testing F1 Score: 0.5289079229122056\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 6, min_samples_split = 4, \n",
    "                             min_samples_leaf = 8, max_leaf_nodes = 16, \n",
    "                             class_weight = 'balanced', random_state = 1)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#predict the training set\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Training F1 Score:\",metrics.f1_score(y_train, y_pred_train))\n",
    "print(\"Testing F1 Score:\",metrics.f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridsearchCV with decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_leaf_nodes_value = range(10, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='entropy', max_depth=6,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=16,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=8,\n",
       "                                              min_samples_split=4,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=1, splitter='best'),\n",
       "             iid='deprecated', n_jobs=None, param_grid={},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create our estimaor\n",
    "clf_cv = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 6, min_samples_split = 4, \n",
    "                             min_samples_leaf = 8, max_leaf_nodes = 16, \n",
    "                             class_weight = 'balanced', random_state = 1)\n",
    "\n",
    "#create the instance of GridSearchCV\n",
    "grid_tree = GridSearchCV(clf_cv, parameters, cv=10, scoring='f1')\n",
    "\n",
    "#fit the Gridsearch to our data\n",
    "grid_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='entropy', max_depth=6, max_features=None,\n",
       "                       max_leaf_nodes=16, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=8,\n",
       "                       min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
       "                       presort='deprecated', random_state=1, splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5289079229122056\n"
     ]
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred = grid_tree.best_estimator_.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf_weighted = LogisticRegression(penalty='l1', tol = .01, max_iter = 5000, \n",
    "                                     solver='saga', class_weight='balanced')\n",
    "\n",
    "lr_clf_weighted.fit(X_train, y_train)\n",
    "\n",
    "y_weighted_test = lr_clf_weighted.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.7790222222222222\n",
      "Precision score:  0.5161064425770309\n",
      "Recall score:  0.5717610550814585\n",
      "Test F1 score:  0.54251012145749\n"
     ]
    }
   ],
   "source": [
    "# checking accuracy\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, y_weighted_test))\n",
    "\n",
    "# checking precision\n",
    "print('Precision score: ', metrics.precision_score(y_test, y_weighted_test))\n",
    "\n",
    "# Checking recall\n",
    "print('Recall score: ', metrics.recall_score(y_test, y_weighted_test))\n",
    "\n",
    "# checking accuracy\n",
    "print('Test F1 score: ', f1_score(y_test, y_weighted_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with Gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(criterion = 'entropy', max_depth = 8, n_estimators = 250, \n",
    "                             min_samples_leaf = 8, min_samples_split = 2, random_state = 1, \n",
    "                             class_weight='balanced', bootstrap=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model to the training data\n",
    "rfc.fit(X_train, y_train)\n",
    "#use the fitted model to predict on the test data\n",
    "rfc_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.7898666666666667\n",
      "Precision score:  0.53960029607698\n",
      "Recall score:  0.5655546935608999\n",
      "Test F1 score:  0.5522727272727272\n"
     ]
    }
   ],
   "source": [
    "# checking accuracy\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, rfc_pred))\n",
    "\n",
    "# checking precision\n",
    "print('Precision score: ', metrics.precision_score(y_test, rfc_pred))\n",
    "\n",
    "# Checking recall\n",
    "print('Recall score: ', metrics.recall_score(y_test, rfc_pred))\n",
    "\n",
    "# checking accuracy\n",
    "print('Test F1 score: ', f1_score(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.66457346e-02, 3.63599124e-03, 1.69199921e-02, 4.26616471e-02,\n",
       "       4.24987403e-02, 3.50427386e-02, 3.02781229e-02, 2.89676915e-02,\n",
       "       3.25868118e-02, 1.38287344e-02, 1.17015094e-02, 7.76399602e-03,\n",
       "       3.18526955e-03, 2.81595243e-03, 3.51456934e-03, 4.43831948e-03,\n",
       "       1.86900489e-03, 2.36098950e-03, 3.57094110e-03, 8.17965708e-02,\n",
       "       2.10784045e-02, 1.74148111e-01, 9.15619290e-03, 3.78247887e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.37387837e-05,\n",
       "       2.71881533e-02, 0.00000000e+00, 1.08405562e-01, 5.28165313e-03,\n",
       "       2.20770106e-04, 4.38200749e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.27155192e-02, 0.00000000e+00, 6.64746333e-02, 1.33919813e-03,\n",
       "       3.21440304e-04, 0.00000000e+00, 0.00000000e+00, 2.64141078e-04,\n",
       "       0.00000000e+00, 8.14106430e-03, 0.00000000e+00, 4.43038262e-02,\n",
       "       6.73561574e-04, 1.94387914e-04, 3.81553345e-05, 0.00000000e+00,\n",
       "       9.19389890e-04, 0.00000000e+00, 4.99708258e-03, 4.59927389e-02,\n",
       "       1.51979594e-03, 2.71686225e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "       4.81648365e-04, 0.00000000e+00, 6.26015496e-03, 3.19754823e-02,\n",
       "       8.86500072e-04, 3.54213528e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "       4.62588935e-04, 0.00000000e+00])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter check 1 \n",
    "# best parameters n = 125, max depth = 7\n",
    "\n",
    "n_estimators_rfc = [250, 275, 300, 325, 350]\n",
    "max_depth_rfc = range(7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter check 1 \n",
    "# best parameters split = 2, leaf = 7, criterior = 'entropy'\n",
    "\n",
    "min_samples_leaf_rfc = range(5,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict_rf = {'max_depth': max_depth_rfc, 'n_estimators': n_estimators_rfc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='entropy',\n",
       "                                              max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=7,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=-1,\n",
       "                                              oob_score=False, random_state=1,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': range(7, 11),\n",
       "                         'n_estimators': [250, 275, 300, 325, 350]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create our estimaor\n",
    "rfc_cv = RandomForestClassifier(criterion = 'entropy',\n",
    "                             min_samples_leaf = 7, min_samples_split = 2, random_state = 1, \n",
    "                             class_weight='balanced', n_jobs = -1)\n",
    "\n",
    "#create the instance of GridSearchCV\n",
    "grid_tree_rfc = GridSearchCV(rfc_cv, param_dict_rf, cv=10, scoring='f1')\n",
    "\n",
    "#fit the Gridsearch to our data\n",
    "grid_tree_rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='entropy', max_depth=8, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=7, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=250,\n",
       "                       n_jobs=-1, oob_score=False, random_state=1, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5518814139110604\n"
     ]
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred_rfc = grid_tree_rfc.best_estimator_.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.f1_score(y_test, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting results on a confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(metrics.confusion_matrix(y_test, rfc_pred), classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating models using voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an ensemble model using the best models from the 3 methods that gave\n",
    "# the best values for the 3 models\n",
    "\n",
    "rfc_en = RandomForestClassifier(criterion = 'entropy', max_depth = 7, n_estimators = 150,\n",
    "                             min_samples_leaf = 7, min_samples_split = 2, random_state = 1, \n",
    "                             class_weight='balanced')\n",
    "\n",
    "lr_clf_en = LogisticRegression(penalty='l1', tol = .01, max_iter = 5000, \n",
    "                                     solver='saga')\n",
    "\n",
    "clf_en = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 6, min_samples_split = 4, \n",
    "                             min_samples_leaf = 8, max_leaf_nodes = 16, \n",
    "                             class_weight = 'balanced', random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(estimators = [('lr', lr_clf_en), ('rf', rfc_en), \n",
    "                                            ('dt', clf_en)], voting = 'hard')\n",
    "\n",
    "# fitting the training data\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_vclf = voting_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking accuracy\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, y_pred_vclf))\n",
    "\n",
    "# checking precision\n",
    "print('Precision score: ', metrics.precision_score(y_test, y_pred_vclf))\n",
    "\n",
    "# Checking recall\n",
    "print('Recall score: ', metrics.recall_score(y_test, y_pred_vclf))\n",
    "\n",
    "# checking accuracy\n",
    "print('Test F1 score: ', f1_score(y_test, y_pred_vclf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing again with only the features that didn't get pushed to 0 in random tree feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(New_X, y2, test_size=0.25, \n",
    "                                                            random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_2 = StandardScaler()\n",
    "scaler_2.fit(X_train_2)\n",
    "X_train_2 = pd.DataFrame(data=scaler_2.transform(X_train_2), columns = New_X.columns)\n",
    "X_test_2 = pd.DataFrame(data=scaler_2.transform(X_test_2), columns = New_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with cleaned up DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_2 = RandomForestClassifier(criterion = 'entropy', max_depth = 8, n_estimators = 300, \n",
    "                             min_samples_leaf = 6, min_samples_split = 4, random_state = 1, \n",
    "                             class_weight='balanced', bootstrap=True, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model to the training data\n",
    "rfc_2.fit(X_train_2, y_train_2)\n",
    "#use the fitted model to predict on the test data\n",
    "rfc_pred_2 = rfc_2.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking accuracy\n",
    "print('Test Accuracy score: ', accuracy_score(y_test_2, rfc_pred_2))\n",
    "\n",
    "# checking precision\n",
    "print('Precision score: ', metrics.precision_score(y_test_2, rfc_pred_2))\n",
    "\n",
    "# Checking recall\n",
    "print('Recall score: ', metrics.recall_score(y_test_2, rfc_pred_2))\n",
    "\n",
    "# checking accuracy\n",
    "print('Test F1 score: ', f1_score(y_test_2, rfc_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_2.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Gridsearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_2 = {'max_depth': range(6, 11), 'n_estimators': [200, 300, 400, 500, 600]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our estimaor\n",
    "rfc_cv_2 = RandomForestClassifier(criterion = 'entropy',\n",
    "                             min_samples_leaf = 7, min_samples_split = 2, random_state = 1, \n",
    "                             class_weight='balanced', n_jobs = -1)\n",
    "\n",
    "#create the instance of GridSearchCV\n",
    "grid_tree_rfc_2 = GridSearchCV(rfc_cv_2, param_grid_2, cv=10, scoring='f1')\n",
    "\n",
    "#fit the Gridsearch to our data\n",
    "grid_tree_rfc_2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = {}\n",
    "for i in range(len(X.columns)):\n",
    "    feature_dict[X.columns[i]] = rfc.feature_importances_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = []\n",
    "\n",
    "for x, y in feature_dict.items():\n",
    "    if y != 0:\n",
    "        final_features.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_X = X[final_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(New_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Features_Selected_by_RF', 'wb') as handle:\n",
    "    pickle.dump(X, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Default_values', 'wb') as handle:\n",
    "    pickle.dump(y, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
